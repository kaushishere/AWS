{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql\n",
        "\n",
        "CREATE TABLE sensor_data (\n",
        "    sensor_id INTEGER,\n",
        "    current_temperature DOUBLE,\n",
        "    status VARCHAR(6),\n",
        "    event_time TIMESTAMP(3),\n",
        "    WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
        ")\n",
        "PARTITIONED BY (sensor_id)\n",
        "WITH (\n",
        "    'connector' = 'kinesis',\n",
        "    'stream' = 'my-input-stream',\n",
        "    'aws.region' = 'us-east-1',\n",
        "    'scan.stream.initpos' = 'LATEST',\n",
        "    'format' = 'json',\n",
        "    'json.timestamp-format.standard' = 'ISO-8601'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql(type=update)\n",
        "\n",
        "SELECT * FROM sensor_data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql(type=update)\n",
        "\n",
        "SELECT sensor_data.status,\n",
        "       COUNT(*) AS num,\n",
        "       AVG(sensor_data.current_temperature) AS avg_current_temperature,\n",
        "       HOP_ROWTIME(event_time, INTERVAL '10' second, INTERVAL '1' minute) as hop_time\n",
        "  FROM sensor_data\n",
        " GROUP BY HOP(event_time, INTERVAL '10' second, INTERVAL '1' minute), sensor_data.status;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql\n",
        "\n",
        "CREATE TABLE sensor_state (\n",
        "    status VARCHAR(20),\n",
        "    num DOUBLE,\n",
        "    avg_current_temperature DOUBLE,\n",
        "    hop_time TIMESTAMP(3)\n",
        ")\n",
        "WITH (\n",
        "'connector' = 'kinesis',\n",
        "'stream' = 'my-output-stream',\n",
        "'aws.region' = 'us-east-1',\n",
        "'scan.stream.initpos' = 'LATEST',\n",
        "'format' = 'json',\n",
        "'json.timestamp-format.standard' = 'ISO-8601');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql(type=update)\n",
        "\n",
        "INSERT INTO sensor_state\n",
        "SELECT sensor_data.status,\n",
        "    COUNT(*) AS num,\n",
        "    AVG(sensor_data.current_temperature) AS avg_current_temperature,\n",
        "    HOP_ROWTIME(event_time, INTERVAL '10' second, INTERVAL '1' minute) as hop_time\n",
        "FROM sensor_data\n",
        "GROUP BY HOP(event_time, INTERVAL '10' second, INTERVAL '1' minute), sensor_data.status;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "The error above is common. According to Reddit, if I deploy the Zeppelin streaming application, the above code will work but the notebook cannot perform the INSERT sql command."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "flink",
      "pygments_lexer": "scala"
    },
    "name": "sensor"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
